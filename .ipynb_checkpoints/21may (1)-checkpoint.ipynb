{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdURsCGhp4AQ"
   },
   "source": [
    "# Imagen: Dogs vs Cats dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVV7aMacsQdr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~eras (/Users/marielalvarez/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle pathlib tensorflow\n",
    "import os, zipfile\n",
    "import pathlib, tensorflow as tf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-R7V6ctPpXBI",
    "outputId": "da07cc56-1824-40e9-d474-1f4058690788"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "zip_path = \"deep-learning.zip\"\n",
    "extract_path = \"deep-learning\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "BASE_DIR   = pathlib.Path(\"deep-learning/deep-learning\")\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "              BASE_DIR / \"train\",\n",
    "              validation_split=0.2, subset=\"training\", seed=123,\n",
    "              image_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "              label_mode=\"binary\")\n",
    "\n",
    "val_ds   = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "              BASE_DIR / \"train\",\n",
    "              validation_split=0.2, subset=\"validation\", seed=123,\n",
    "              image_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "              label_mode=\"binary\")\n",
    "\n",
    "test_ds  = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "              BASE_DIR / \"test\",\n",
    "              shuffle=False,\n",
    "              image_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "              label_mode=\"binary\")\n",
    "\n",
    "print(\"Clases detectadas:\", train_ds.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vJGjqTnyxV0",
    "outputId": "e25601bb-7c67-4665-cacf-4bba9cd232eb"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tK_hPR0byX0S",
    "outputId": "cc180ad2-3f29-4213-8d74-c211ad41a45a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "image_model = keras.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(224, 224, 3)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "image_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "image_model.fit(train_ds,\n",
    "          epochs=5,\n",
    "          validation_data=val_ds)\n",
    "\n",
    "test_loss, test_acc = image_model.evaluate(test_ds)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgemOpp10Rxp",
    "outputId": "0c454ad3-4588-4da9-ec46-a14fbfc893ac"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "y_pred_prob = image_model.predict(test_ds)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "print(classification_report(y_true, y_pred, target_names=test_ds.class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeTIPUNep6Cr"
   },
   "source": [
    "# Text SMS Spam Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q0nzDH1ICmg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lo-5UZhgFbES"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")[['v1', 'v2']]\n",
    "df = df.rename(columns={'v1': 'label', 'v2': 'text'}).copy()\n",
    "text_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M_xshPyFjhA"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['label'] = df['label'].str.strip().map({'ham': 0, 'spam': 1}).astype('int32')\n",
    "df['text']  = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uc7ZrY7i2Ndr",
    "outputId": "efa3e332-f611-42fc-8550-cb6f5c01e513"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dense\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "MAX_TOKENS = 10000\n",
    "MAX_LEN = 100\n",
    "EMBED_DIM = 16\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_TOKENS,\n",
    "                               output_sequence_length=MAX_LEN)\n",
    "vectorizer.adapt(X_train)\n",
    "\n",
    "text_model = Sequential([\n",
    "    vectorizer,\n",
    "    Embedding(MAX_TOKENS, EMBED_DIM),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "text_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train_np = X_train.to_numpy(dtype=object)\n",
    "X_test_np  = X_test.to_numpy(dtype=object)\n",
    "\n",
    "text_model.fit(X_train_np, y_train.to_numpy(),\n",
    "          epochs=5, batch_size=32,\n",
    "          validation_split=0.1)\n",
    "\n",
    "loss, acc = text_model.evaluate(X_test_np, y_test.to_numpy())\n",
    "print(f\"Test accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HH3T3k0SI0Ir",
    "outputId": "7695bcf1-3737-408b-a2f1-c90729aeaa5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_probs = text_model.predict(X_test_np)\n",
    "\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred_labels,\n",
    "                            target_names=['ham', 'spam']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bW3cviC4p91f"
   },
   "source": [
    "# Regression: House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qusuiSjPp_4P"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "rILq8XxG6GwX",
    "outputId": "e57bebe9-3a04-4bf7-ea53-91c60e977f27"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eDJ0ncSJt2J",
    "outputId": "64c06631-8b6e-41f4-9a7a-3724fb054a33"
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk_7osPR6JAS",
    "outputId": "750f5c89-c613-4510-ca28-99ebfdc5aa41"
   },
   "outputs": [],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLdQqoC06WbI",
    "outputId": "16ce3096-2bb9-427e-9faa-dd9da4938822"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras import layers, Sequential\n",
    "train = train.fillna(train.mean(numeric_only=True))\n",
    "y = train.pop('SalePrice')\n",
    "X = train.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_cols = X_train.select_dtypes(\n",
    "    include=['object', 'category']).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(\n",
    "    exclude=['object', 'category']).columns.tolist()\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "        ('num', MinMaxScaler(),                     num_cols)\n",
    "    ])\n",
    "\n",
    "X_train_prep = pre.fit_transform(X_train)\n",
    "X_test_prep  = pre.transform(X_test)\n",
    "input_dim = X_train_prep.shape[1]\n",
    "regression_model = Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "regression_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "regression_model.fit(X_train_prep, y_train,\n",
    "          epochs=5, batch_size=32,\n",
    "          validation_split=0.1)\n",
    "\n",
    "loss, mae = regression_model.evaluate(X_test_prep, y_test)\n",
    "print(f\"Test MAE: {mae:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6VOhfGc_atp",
    "outputId": "1cf421ca-c9da-4821-fc67-91fa7702fb4c"
   },
   "outputs": [],
   "source": [
    "loss, mae = regression_model.evaluate(X_test_prep, y_test)\n",
    "print(f\"Test MAE: {mae:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gI9bvvj1KR-T",
    "outputId": "647167c6-4ce0-4c18-f228-1df3007b695d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import math\n",
    "y_pred = regression_model.predict(X_test_prep).squeeze()\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE:  ${mae:,.0f}\")\n",
    "print(f\"RMSE: ${rmse:,.0f}\")\n",
    "print(f\"RÂ² score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGm3ccFWy7kv"
   },
   "outputs": [],
   "source": [
    "with open(\"text_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(text_model, f)\n",
    "\n",
    "with open(\"image_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(image_model, f)\n",
    "\n",
    "with open(\"regression_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(regression_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jatgyxV_8sd0"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
